{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "DCGAN_500_images.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9w6dBsi2fnCV"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxRtSO1Lfm_8"
      },
      "source": [
        "# Implementation of Deep Convolutional GANs\n",
        "Reference: https://arxiv.org/pdf/1511.06434.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5Xst7umfnAA"
      },
      "source": [
        "# Run the comment below only when using Google Colab\n",
        "# !pip install torch torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9kSQ1Twfsm8",
        "outputId": "d3b56f42-fc33-4874-deb1-437a3b271593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Mount the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLB-QIwE27f8",
        "outputId": "93e6d103-0159-4464-fcca-95bb8277f149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "!pip install torch==1.5.1+cu92 torchvision==0.6.1+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu92\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torch-1.5.1%2Bcu92-cp36-cp36m-linux_x86_64.whl (604.8MB)\n",
            "\u001b[K     |████████████████████████████████| 604.8MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu92\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.6.1%2Bcu92-cp36-cp36m-linux_x86_64.whl (6.5MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 20.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu92) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu92) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu92) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.5.1+cu92 torchvision-0.6.1+cu92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTOto3f6gS0j"
      },
      "source": [
        "!cp '/content/drive/My Drive/eva4_phase2_datasets/final_car_images.zip' .\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AdpqXZYhWXR"
      },
      "source": [
        "!unzip -qq final_car_images.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQTyxbp2hJSD"
      },
      "source": [
        "!mkdir -p '/content/drive/My Drive/eva4_phase2_output/gan_new_collage_images_500'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPT65yZAfnAX"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd3pufcSfnAl"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RGaHSj-fnAz"
      },
      "source": [
        "import numpy as np\n",
        "import datetime\n",
        "import os, sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DO7tYxEfnA5"
      },
      "source": [
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQDzSQuQfnBB"
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6UjuBxZfnBI"
      },
      "source": [
        "from matplotlib.pyplot import imshow, imsave\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9BDYs9rfnBN"
      },
      "source": [
        "MODEL_NAME = 'DCGAN'\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlevCNUjfnBR"
      },
      "source": [
        "#IMAGE_DIM = (32, 32, 3)\n",
        "IMAGE_DIM = (128, 128, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOfKvLnNfnBW"
      },
      "source": [
        "def get_sample_image(G, n_noise):\n",
        "    \"\"\"\n",
        "        save sample 100 images\n",
        "    \"\"\"\n",
        "    z = torch.randn(10, n_noise).to(DEVICE)\n",
        "    #y_hat = G(z).view(10, 3, 32, 32).permute(0, 2, 3, 1) # (100, 28, 28)\n",
        "    y_hat = G(z).view(10, 3, 128, 128).permute(0, 2, 3, 1) # (100, 28, 28)\n",
        "    result = (y_hat.detach().cpu().numpy()+1)/2.\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCyDtQj1fnBa"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "        Convolutional Discriminator for MNIST\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channel=1, num_classes=1):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            # 28 -> 14\n",
        "            nn.Conv2d(in_channel, 512, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # 14 -> 7\n",
        "            nn.Conv2d(512, 256, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # 7 -> 4\n",
        "            nn.Conv2d(256, 128, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # \n",
        "            nn.Conv2d(128, 128, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "        )        \n",
        "        self.fc = nn.Sequential(\n",
        "            # reshape input, 128 -> 1\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, y=None):\n",
        "        y_ = self.conv(x)\n",
        "        y_ = y_.view(y_.size(0), -1)\n",
        "        y_ = self.fc(y_)\n",
        "        return y_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YvJxNcOfnBf"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "        Convolutional Generator for MNIST\n",
        "    \"\"\"\n",
        "    def __init__(self, out_channel=1, input_size=100, num_classes=784):\n",
        "        super(Generator, self).__init__()\n",
        "        assert IMAGE_DIM[0] % 2**4 == 0, 'Should be divided 16'\n",
        "        self.init_dim = (IMAGE_DIM[0] // 2**4, IMAGE_DIM[1] // 2**4)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_size, self.init_dim[0]*self.init_dim[1]*512),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            # x2\n",
        "            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            # x2\n",
        "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            # x2\n",
        "            nn.ConvTranspose2d(128, 128, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            # x2\n",
        "            nn.ConvTranspose2d(128, out_channel, 4, stride=2, padding=1, bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x, y=None):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        y_ = self.fc(x)\n",
        "        y_ = y_.view(y_.size(0), 512, self.init_dim[0], self.init_dim[1])\n",
        "        y_ = self.conv(y_)\n",
        "        return y_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fElt3elWfnBk"
      },
      "source": [
        "class CARS(Dataset):\n",
        "    '''\n",
        "    CARS Dataset\n",
        "    You should download this dataset from below url.\n",
        "    url: https://ai.stanford.edu/~jkrause/cars/car_dataset.html\n",
        "    '''\n",
        "    def __init__(self, data_path, transform=None):\n",
        "        '''\n",
        "        Args:\n",
        "            data_path (str): path to dataset\n",
        "        '''\n",
        "        self.data_path = data_path\n",
        "        self.transform = transform\n",
        "        self.fpaths = sorted(glob.glob(os.path.join(data_path, '*.jpg')))\n",
        "        #gray_lst = [266, 1085, 2176, 3048, 3439, 3469, 3539, 4577, 4848, 5177, 5502, 5713, 6947, 7383, 7693, 7774, 8137, 8144]\n",
        "        #for num in gray_lst:\n",
        "        #    self.fpaths.remove(os.path.join(data_path, '{:05d}.jpg'.format(num)))\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img = self.transform(Image.open(self.fpaths[idx]))\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fpaths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1cHsL3PfnBp"
      },
      "source": [
        "D = Discriminator(in_channel=IMAGE_DIM[-1]).to(DEVICE)\n",
        "G = Generator(out_channel=IMAGE_DIM[-1]).to(DEVICE)\n",
        "# D.load_state_dict('D_dc.pkl')\n",
        "# G.load_state_dict('G_dc.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAR4DGRMfnBs"
      },
      "source": [
        "transform = transforms.Compose([transforms.Resize((IMAGE_DIM[0],IMAGE_DIM[1])),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5, 0.5, 0.5),\n",
        "                                std=(0.5, 0.5, 0.5))\n",
        "                               ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c3duyNtfnBx"
      },
      "source": [
        "dataset = CARS(data_path='/content', transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTrSMZmnfnB0"
      },
      "source": [
        "batch_size = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqHogHfFfnB5"
      },
      "source": [
        "#data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=8)\n",
        "data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4sR1j0LfnB7",
        "outputId": "20316a64-7864-467c-f560-f4f9bf51262d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample= next(iter(data_loader))\n",
        "print(sample.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 3, 128, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEKj9dTJfnCA"
      },
      "source": [
        "criterion = nn.BCELoss()\n",
        "D_opt = torch.optim.Adam(D.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
        "G_opt = torch.optim.Adam(G.parameters(), lr=0.001, betas=(0.5, 0.999))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfSHow3ifnCE"
      },
      "source": [
        "max_epoch = 10000\n",
        "step = 0\n",
        "n_critic = 1 # for training more k steps about Discriminator\n",
        "n_noise = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "disYUWHZfnCK"
      },
      "source": [
        "D_labels = torch.ones([batch_size, 1]).to(DEVICE) # Discriminator Label to real\n",
        "D_fakes = torch.zeros([batch_size, 1]).to(DEVICE) # Discriminator Label to fake"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwKxf1AhCT79"
      },
      "source": [
        "def generate_and_save_collage(img_list, path):\n",
        "    new_im = Image.new('RGB', (640 , 256))\n",
        "    for i in range(2):\n",
        "        for j in range(int(len(img_list)/2)):\n",
        "            img_array= 255*img_list[i*5 + j]\n",
        "            pil_img = Image.fromarray(img_array.astype('uint8'), 'RGB')\n",
        "            new_im.paste(pil_img, (128*j, 128*i))\n",
        "    new_im.save(path)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2AbPdqH7fnCO",
        "outputId": "5fcf87da-c7a5-444a-9a46-b6e01697c3e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(max_epoch):\n",
        "    for idx, images in enumerate(data_loader):\n",
        "        # Training Discriminator\n",
        "        x = images.to(DEVICE)\n",
        "        x_outputs = D(x)\n",
        "        D_x_loss = criterion(x_outputs, D_labels)\n",
        "\n",
        "        z = torch.randn(batch_size, n_noise).to(DEVICE)\n",
        "        z_outputs = D(G(z))\n",
        "        D_z_loss = criterion(z_outputs, D_fakes)\n",
        "        D_loss = D_x_loss + D_z_loss\n",
        "        \n",
        "        D.zero_grad()\n",
        "        D_loss.backward()\n",
        "        D_opt.step()\n",
        "\n",
        "        if step % n_critic == 0:\n",
        "            # Training Generator\n",
        "            z = torch.randn(batch_size, n_noise).to(DEVICE)\n",
        "            z_outputs = D(G(z))\n",
        "            G_loss = criterion(z_outputs, D_labels)\n",
        "\n",
        "            D.zero_grad()\n",
        "            G.zero_grad()\n",
        "            G_loss.backward()\n",
        "            G_opt.step()\n",
        "        \n",
        "        if step % 500 == 0:\n",
        "            dt = datetime.datetime.now().strftime('%H:%M:%S')\n",
        "            print('Epoch: {}/{}, Step: {}, D Loss: {:.4f}, G Loss: {:.4f}, Time:{}'.format(epoch, max_epoch, step, D_loss.item(), G_loss.item(), dt))\n",
        "            G.eval()\n",
        "            img = get_sample_image(G, n_noise)\n",
        "            image_save_path = '/content/drive/My Drive/eva4_phase2_output/gan_new_collage_images_500/{}_step{:05d}.jpg'.format(MODEL_NAME, step)\n",
        "\n",
        "            #generate_and_save_collage(img, '/content/drive/My Drive/eva4_phase2_datasets/gan_new_collage_images/{}_step{:05d}.jpg'.format(MODEL_NAME, step))\n",
        "            generate_and_save_collage(img, image_save_path)\n",
        "            torch.save(G.state_dict(), '/content/drive/My Drive/eva4_phase2_models/gan_generate_500_model_step_' + str(step) +\".pth\" )\n",
        "            #imsave('/content/drive/My Drive/eva4_phase2_datasets/gan_new_collage_images/{}_step{:05d}.jpg'.format(MODEL_NAME, step), img[0])\n",
        "\n",
        "            G.train()\n",
        "    step += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0/10000, Step: 0, D Loss: 1.3858, G Loss: 0.7245, Time:17:02:12\n",
            "Epoch: 0/10000, Step: 0, D Loss: 1.3926, G Loss: 0.7309, Time:17:02:13\n",
            "Epoch: 0/10000, Step: 0, D Loss: 1.3872, G Loss: 0.7279, Time:17:02:13\n",
            "Epoch: 0/10000, Step: 0, D Loss: 1.3649, G Loss: 0.7322, Time:17:02:14\n",
            "Epoch: 0/10000, Step: 0, D Loss: 1.3483, G Loss: 0.7410, Time:17:02:15\n",
            "Epoch: 0/10000, Step: 0, D Loss: 1.3485, G Loss: 0.7369, Time:17:02:16\n",
            "Epoch: 500/10000, Step: 500, D Loss: 1.3160, G Loss: 1.3870, Time:17:16:25\n",
            "Epoch: 500/10000, Step: 500, D Loss: 0.9190, G Loss: 1.3933, Time:17:16:26\n",
            "Epoch: 500/10000, Step: 500, D Loss: 0.9231, G Loss: 1.2930, Time:17:16:26\n",
            "Epoch: 500/10000, Step: 500, D Loss: 0.9922, G Loss: 1.0751, Time:17:16:27\n",
            "Epoch: 500/10000, Step: 500, D Loss: 0.9570, G Loss: 1.2990, Time:17:16:28\n",
            "Epoch: 500/10000, Step: 500, D Loss: 0.8369, G Loss: 1.3406, Time:17:16:29\n",
            "Epoch: 1000/10000, Step: 1000, D Loss: 0.4255, G Loss: 2.6621, Time:17:30:38\n",
            "Epoch: 1000/10000, Step: 1000, D Loss: 0.1875, G Loss: 3.4437, Time:17:30:39\n",
            "Epoch: 1000/10000, Step: 1000, D Loss: 0.1260, G Loss: 3.7849, Time:17:30:39\n",
            "Epoch: 1000/10000, Step: 1000, D Loss: 0.1172, G Loss: 3.4233, Time:17:30:40\n",
            "Epoch: 1000/10000, Step: 1000, D Loss: 0.4875, G Loss: 1.4590, Time:17:30:41\n",
            "Epoch: 1000/10000, Step: 1000, D Loss: 0.5522, G Loss: 3.4462, Time:17:30:41\n",
            "Epoch: 1500/10000, Step: 1500, D Loss: 0.0013, G Loss: 7.3188, Time:17:44:51\n",
            "Epoch: 1500/10000, Step: 1500, D Loss: 0.0016, G Loss: 7.3042, Time:17:44:52\n",
            "Epoch: 1500/10000, Step: 1500, D Loss: 0.0011, G Loss: 7.2889, Time:17:44:52\n",
            "Epoch: 1500/10000, Step: 1500, D Loss: 0.0011, G Loss: 7.2652, Time:17:44:53\n",
            "Epoch: 1500/10000, Step: 1500, D Loss: 0.0009, G Loss: 7.3986, Time:17:44:54\n",
            "Epoch: 1500/10000, Step: 1500, D Loss: 0.0008, G Loss: 7.4991, Time:17:44:55\n",
            "Epoch: 2000/10000, Step: 2000, D Loss: 0.0001, G Loss: 9.8529, Time:17:59:03\n",
            "Epoch: 2000/10000, Step: 2000, D Loss: 0.0001, G Loss: 9.8585, Time:17:59:04\n",
            "Epoch: 2000/10000, Step: 2000, D Loss: 0.0002, G Loss: 9.8478, Time:17:59:04\n",
            "Epoch: 2000/10000, Step: 2000, D Loss: 0.0001, G Loss: 9.8338, Time:17:59:05\n",
            "Epoch: 2000/10000, Step: 2000, D Loss: 0.0001, G Loss: 9.8704, Time:17:59:06\n",
            "Epoch: 2000/10000, Step: 2000, D Loss: 0.0001, G Loss: 9.8506, Time:17:59:07\n",
            "Epoch: 2500/10000, Step: 2500, D Loss: 0.9598, G Loss: 1.3297, Time:18:13:15\n",
            "Epoch: 2500/10000, Step: 2500, D Loss: 0.8507, G Loss: 1.3496, Time:18:13:16\n",
            "Epoch: 2500/10000, Step: 2500, D Loss: 0.9341, G Loss: 1.2841, Time:18:13:16\n",
            "Epoch: 2500/10000, Step: 2500, D Loss: 0.8928, G Loss: 1.7462, Time:18:13:17\n",
            "Epoch: 2500/10000, Step: 2500, D Loss: 1.1016, G Loss: 0.6802, Time:18:13:18\n",
            "Epoch: 2500/10000, Step: 2500, D Loss: 0.9114, G Loss: 2.4704, Time:18:13:19\n",
            "Epoch: 3000/10000, Step: 3000, D Loss: 0.2463, G Loss: 2.6594, Time:18:27:29\n",
            "Epoch: 3000/10000, Step: 3000, D Loss: 0.1609, G Loss: 3.6388, Time:18:27:30\n",
            "Epoch: 3000/10000, Step: 3000, D Loss: 0.4663, G Loss: 2.3732, Time:18:27:30\n",
            "Epoch: 3000/10000, Step: 3000, D Loss: 0.3514, G Loss: 2.0203, Time:18:27:31\n",
            "Epoch: 3000/10000, Step: 3000, D Loss: 0.2136, G Loss: 3.2627, Time:18:27:32\n",
            "Epoch: 3000/10000, Step: 3000, D Loss: 0.1403, G Loss: 3.5279, Time:18:27:33\n",
            "Epoch: 3500/10000, Step: 3500, D Loss: 0.0877, G Loss: 4.5550, Time:18:41:43\n",
            "Epoch: 3500/10000, Step: 3500, D Loss: 0.0350, G Loss: 4.2125, Time:18:41:43\n",
            "Epoch: 3500/10000, Step: 3500, D Loss: 0.2375, G Loss: 3.1517, Time:18:41:44\n",
            "Epoch: 3500/10000, Step: 3500, D Loss: 0.1522, G Loss: 3.4748, Time:18:41:44\n",
            "Epoch: 3500/10000, Step: 3500, D Loss: 0.2679, G Loss: 3.6086, Time:18:41:45\n",
            "Epoch: 3500/10000, Step: 3500, D Loss: 0.0864, G Loss: 4.2427, Time:18:41:46\n",
            "Epoch: 4000/10000, Step: 4000, D Loss: 0.0012, G Loss: 7.2005, Time:18:55:55\n",
            "Epoch: 4000/10000, Step: 4000, D Loss: 0.0009, G Loss: 7.2708, Time:18:55:56\n",
            "Epoch: 4000/10000, Step: 4000, D Loss: 0.0010, G Loss: 7.3301, Time:18:55:56\n",
            "Epoch: 4000/10000, Step: 4000, D Loss: 0.0010, G Loss: 7.6039, Time:18:55:57\n",
            "Epoch: 4000/10000, Step: 4000, D Loss: 0.0009, G Loss: 7.5148, Time:18:55:58\n",
            "Epoch: 4000/10000, Step: 4000, D Loss: 0.0007, G Loss: 7.7897, Time:18:55:59\n",
            "Epoch: 4500/10000, Step: 4500, D Loss: 0.0001, G Loss: 10.0773, Time:19:10:07\n",
            "Epoch: 4500/10000, Step: 4500, D Loss: 0.0001, G Loss: 10.1342, Time:19:10:08\n",
            "Epoch: 4500/10000, Step: 4500, D Loss: 0.0001, G Loss: 10.1980, Time:19:10:08\n",
            "Epoch: 4500/10000, Step: 4500, D Loss: 0.0001, G Loss: 10.0712, Time:19:10:09\n",
            "Epoch: 4500/10000, Step: 4500, D Loss: 0.0001, G Loss: 10.1672, Time:19:10:10\n",
            "Epoch: 4500/10000, Step: 4500, D Loss: 0.0000, G Loss: 10.1873, Time:19:10:11\n",
            "Epoch: 5000/10000, Step: 5000, D Loss: 0.0000, G Loss: 11.6834, Time:19:24:19\n",
            "Epoch: 5000/10000, Step: 5000, D Loss: 0.0000, G Loss: 11.8692, Time:19:24:20\n",
            "Epoch: 5000/10000, Step: 5000, D Loss: 0.0000, G Loss: 11.7685, Time:19:24:20\n",
            "Epoch: 5000/10000, Step: 5000, D Loss: 0.0000, G Loss: 11.6927, Time:19:24:21\n",
            "Epoch: 5000/10000, Step: 5000, D Loss: 0.0000, G Loss: 11.7057, Time:19:24:22\n",
            "Epoch: 5000/10000, Step: 5000, D Loss: 0.0000, G Loss: 11.7959, Time:19:24:22\n",
            "Epoch: 5500/10000, Step: 5500, D Loss: 0.0000, G Loss: 13.4004, Time:19:38:31\n",
            "Epoch: 5500/10000, Step: 5500, D Loss: 0.0000, G Loss: 13.3855, Time:19:38:31\n",
            "Epoch: 5500/10000, Step: 5500, D Loss: 0.0000, G Loss: 13.3641, Time:19:38:32\n",
            "Epoch: 5500/10000, Step: 5500, D Loss: 0.0000, G Loss: 13.3977, Time:19:38:33\n",
            "Epoch: 5500/10000, Step: 5500, D Loss: 0.0000, G Loss: 13.3694, Time:19:38:34\n",
            "Epoch: 5500/10000, Step: 5500, D Loss: 0.0000, G Loss: 13.3757, Time:19:38:35\n",
            "Epoch: 6000/10000, Step: 6000, D Loss: 0.0000, G Loss: 14.8042, Time:19:52:43\n",
            "Epoch: 6000/10000, Step: 6000, D Loss: 0.0000, G Loss: 14.8304, Time:19:52:44\n",
            "Epoch: 6000/10000, Step: 6000, D Loss: 0.0000, G Loss: 14.8022, Time:19:52:44\n",
            "Epoch: 6000/10000, Step: 6000, D Loss: 0.0000, G Loss: 14.8059, Time:19:52:45\n",
            "Epoch: 6000/10000, Step: 6000, D Loss: 0.0000, G Loss: 14.8102, Time:19:52:46\n",
            "Epoch: 6000/10000, Step: 6000, D Loss: 0.0000, G Loss: 14.8438, Time:19:52:47\n",
            "Epoch: 6500/10000, Step: 6500, D Loss: 0.0000, G Loss: 16.1663, Time:20:06:55\n",
            "Epoch: 6500/10000, Step: 6500, D Loss: 0.0000, G Loss: 16.1641, Time:20:06:55\n",
            "Epoch: 6500/10000, Step: 6500, D Loss: 0.0000, G Loss: 16.1252, Time:20:06:56\n",
            "Epoch: 6500/10000, Step: 6500, D Loss: 0.0000, G Loss: 16.1173, Time:20:06:57\n",
            "Epoch: 6500/10000, Step: 6500, D Loss: 0.0000, G Loss: 16.1278, Time:20:06:58\n",
            "Epoch: 6500/10000, Step: 6500, D Loss: 0.0000, G Loss: 16.1581, Time:20:06:58\n",
            "Epoch: 7000/10000, Step: 7000, D Loss: 0.0000, G Loss: 17.4955, Time:20:21:05\n",
            "Epoch: 7000/10000, Step: 7000, D Loss: 0.0000, G Loss: 17.5446, Time:20:21:06\n",
            "Epoch: 7000/10000, Step: 7000, D Loss: 0.0000, G Loss: 17.4727, Time:20:21:06\n",
            "Epoch: 7000/10000, Step: 7000, D Loss: 0.0000, G Loss: 17.4930, Time:20:21:07\n",
            "Epoch: 7000/10000, Step: 7000, D Loss: 0.0000, G Loss: 17.4666, Time:20:21:08\n",
            "Epoch: 7000/10000, Step: 7000, D Loss: 0.0000, G Loss: 17.4915, Time:20:21:08\n",
            "Epoch: 7500/10000, Step: 7500, D Loss: 0.0000, G Loss: 18.7222, Time:20:35:14\n",
            "Epoch: 7500/10000, Step: 7500, D Loss: 0.0000, G Loss: 18.7081, Time:20:35:14\n",
            "Epoch: 7500/10000, Step: 7500, D Loss: 0.0000, G Loss: 18.7139, Time:20:35:15\n",
            "Epoch: 7500/10000, Step: 7500, D Loss: 0.0000, G Loss: 18.7265, Time:20:35:16\n",
            "Epoch: 7500/10000, Step: 7500, D Loss: 0.0000, G Loss: 18.7396, Time:20:35:17\n",
            "Epoch: 7500/10000, Step: 7500, D Loss: 0.0000, G Loss: 18.7478, Time:20:35:18\n",
            "Epoch: 8000/10000, Step: 8000, D Loss: 0.0000, G Loss: 19.8793, Time:20:49:22\n",
            "Epoch: 8000/10000, Step: 8000, D Loss: 0.0000, G Loss: 19.8816, Time:20:49:23\n",
            "Epoch: 8000/10000, Step: 8000, D Loss: 0.0000, G Loss: 19.8725, Time:20:49:23\n",
            "Epoch: 8000/10000, Step: 8000, D Loss: 0.0000, G Loss: 19.8777, Time:20:49:24\n",
            "Epoch: 8000/10000, Step: 8000, D Loss: 0.0000, G Loss: 19.8575, Time:20:49:25\n",
            "Epoch: 8000/10000, Step: 8000, D Loss: 0.0000, G Loss: 19.9075, Time:20:49:26\n",
            "Epoch: 8500/10000, Step: 8500, D Loss: 0.0000, G Loss: 20.4993, Time:21:03:30\n",
            "Epoch: 8500/10000, Step: 8500, D Loss: 0.0000, G Loss: 20.5290, Time:21:03:31\n",
            "Epoch: 8500/10000, Step: 8500, D Loss: 0.0000, G Loss: 20.5066, Time:21:03:31\n",
            "Epoch: 8500/10000, Step: 8500, D Loss: 0.0000, G Loss: 20.5077, Time:21:03:32\n",
            "Epoch: 8500/10000, Step: 8500, D Loss: 0.0000, G Loss: 20.5531, Time:21:03:33\n",
            "Epoch: 8500/10000, Step: 8500, D Loss: 0.0000, G Loss: 20.5292, Time:21:03:34\n",
            "Epoch: 9000/10000, Step: 9000, D Loss: 0.0000, G Loss: 21.8952, Time:21:17:39\n",
            "Epoch: 9000/10000, Step: 9000, D Loss: 0.0000, G Loss: 21.8953, Time:21:17:39\n",
            "Epoch: 9000/10000, Step: 9000, D Loss: 0.0000, G Loss: 21.8870, Time:21:17:40\n",
            "Epoch: 9000/10000, Step: 9000, D Loss: 0.0000, G Loss: 21.9148, Time:21:17:41\n",
            "Epoch: 9000/10000, Step: 9000, D Loss: 0.0000, G Loss: 21.8815, Time:21:17:42\n",
            "Epoch: 9000/10000, Step: 9000, D Loss: 0.0000, G Loss: 21.8965, Time:21:17:43\n",
            "Epoch: 9500/10000, Step: 9500, D Loss: 0.5824, G Loss: 6.4205, Time:21:31:52\n",
            "Epoch: 9500/10000, Step: 9500, D Loss: 0.2239, G Loss: 5.3494, Time:21:31:53\n",
            "Epoch: 9500/10000, Step: 9500, D Loss: 0.2976, G Loss: 2.8707, Time:21:31:53\n",
            "Epoch: 9500/10000, Step: 9500, D Loss: 0.1739, G Loss: 3.2143, Time:21:31:54\n",
            "Epoch: 9500/10000, Step: 9500, D Loss: 0.1163, G Loss: 3.9056, Time:21:31:55\n",
            "Epoch: 9500/10000, Step: 9500, D Loss: 0.1268, G Loss: 4.7227, Time:21:31:55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX-Xo1k3B__l",
        "outputId": "8e84f537-7ba5-43f3-9eaa-f20c402608b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "MODEL_PATH = '/content/drive/My Drive/eva4_phase2_models/gan_generate_model_step_2500.pth'\n",
        "model_cpu = G.to('cpu')\n",
        "traced_model = torch.jit.trace(model_cpu, torch.randn(1,3, 224, 224))\n",
        "traced_model.save(MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-9df341b1ea08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mMODEL_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/eva4_phase2_models/gan_generate_model_step_2500.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtraced_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtraced_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    873\u001b[0m         return trace_module(func, {'forward': example_inputs}, None,\n\u001b[1;32m    874\u001b[0m                             \u001b[0mcheck_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m                             check_tolerance, _force_outplace, _module_class)\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m     if (hasattr(func, '__self__') and isinstance(func.__self__, torch.nn.Module) and\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"forward\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0mexample_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_method_from_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_lookup_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0mcheck_trace_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-56eae98358ec>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_dim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_dim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1608\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [1 x 150528], m2: [100 x 32768] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:41"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tegk3ZIrfnCS"
      },
      "source": [
        "!ls -l '/content/drive/My Drive/eva4_phase2_models/gan_generator_200.pt'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w6dBsi2fnCV"
      },
      "source": [
        "## Sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4TjhvqHfnCW",
        "outputId": "47879eaf-a281-4de9-ec96-dfa8012bd01b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "# generation to image\n",
        "G.eval()\n",
        "imshow(get_sample_image(G, n_noise)[9])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f566a0527b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN2gg096fnCZ",
        "outputId": "c1a71e90-5327-4bd4-fa48-c8abdf0af4a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "# Real Image\n",
        "t = Image.open(dataset.fpaths[100])\n",
        "t = (transform(t).permute(1, 2, 0)+1)/2.\n",
        "imshow(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f566a1cad68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAfrKCoTfnCe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjviKzsefnCh"
      },
      "source": [
        "def save_checkpoint(state, file_name='checkpoint.pth.tar'):\n",
        "    torch.save(state, file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHAHbf1VfnCl"
      },
      "source": [
        "# Saving params.\n",
        "# torch.save(D.state_dict(), 'D_c.pkl')\n",
        "# torch.save(G.state_dict(), 'G_c.pkl')\n",
        "save_checkpoint({'epoch': epoch + 1,\n",
        "                 'D':D.state_dict(),\n",
        "                 'G':G.state_dict(),\n",
        "                 'd_optim': D_opt.state_dict(),\n",
        "                 'g_optim' : G_opt.state_dict()},\n",
        "                '/content/drive/My Drive/eva4_phase2_models/dcgan.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRRUesJAfnCn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}